input {
  # Application logs via TCP
  tcp {
    port => 5000
    codec => json
    type => "application"
  }

  # System logs via UDP
  udp {
    port => 5000
    codec => json
    type => "system"
  }

  # Docker logs from Filebeat
  beats {
    port => 5044
    type => "docker"
  }

  # HTTP input for direct log shipping
  http {
    port => 8080
    codec => json
    type => "http"
  }
}

filter {
  # Parse timestamp
  date {
    match => [ "timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss", "yyyy-MM-dd'T'HH:mm:ss.SSSZ" ]
    target => "@timestamp"
  }

  # Parse application logs
  if [type] == "application" {
    # Extract service name from logger
    if [logger] {
      mutate {
        add_field => { "service" => "%{logger}" }
      }
    }

    # Parse error stack traces
    if [error] {
      mutate {
        add_field => { 
          "error_type" => "%{[error][type]}"
          "error_message" => "%{[error][message]}"
        }
      }
    }

    # Extract user context
    if [userId] {
      mutate {
        add_field => { "user_id" => "%{userId}" }
      }
    }

    # Extract job context
    if [jobId] {
      mutate {
        add_field => { "job_id" => "%{jobId}" }
      }
    }

    # Performance metrics
    if [duration] {
      mutate {
        convert => { "duration" => "integer" }
      }
    }
  }

  # Parse Docker logs
  if [type] == "docker" {
    json {
      source => "message"
      target => "docker"
    }

    # Extract container info
    mutate {
      add_field => {
        "container_id" => "%{[docker][container][id]}"
        "container_name" => "%{[docker][container][name]}"
        "container_image" => "%{[docker][container][image]}"
      }
    }
  }

  # Parse HTTP request logs
  if [path] {
    grok {
      match => {
        "message" => "%{COMBINEDAPACHELOG}"
      }
      tag_on_failure => ["_grok_parse_failure"]
    }

    # Extract API endpoint
    grok {
      match => {
        "request" => "(?<method>GET|POST|PUT|DELETE|PATCH) (?<endpoint>/[^ ]*)"
      }
      tag_on_failure => ["_grok_api_parse_failure"]
    }

    # Response time tracking
    if [response_time] {
      mutate {
        convert => { "response_time" => "float" }
      }
    }
  }

  # Security event detection
  if [message] =~ /(?i)(unauthorized|forbidden|auth.*fail|invalid.*token|csrf|xss|injection)/ {
    mutate {
      add_tag => [ "security_event" ]
      add_field => { "alert_type" => "security" }
    }
  }

  # Error detection
  if [level] == "error" or [severity] == "error" {
    mutate {
      add_tag => [ "error" ]
      add_field => { "alert_type" => "error" }
    }
  }

  # Performance issues detection
  if [duration] and [duration] > 5000 {
    mutate {
      add_tag => [ "slow_request" ]
      add_field => { "alert_type" => "performance" }
    }
  }

  # Add environment metadata
  mutate {
    add_field => {
      "environment" => "${NODE_ENV:development}"
      "application" => "finishthisidea"
      "version" => "${APP_VERSION:unknown}"
    }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => [ "host", "port", "@version" ]
  }
}

output {
  # Output to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "finishthisidea-%{type}-%{+YYYY.MM.dd}"
    template_name => "finishthisidea"
    template => "/usr/share/logstash/templates/finishthisidea.json"
    template_overwrite => true
  }

  # Output security events to separate index
  if "security_event" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "finishthisidea-security-%{+YYYY.MM.dd}"
    }
  }

  # Output errors to separate index
  if "error" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "finishthisidea-errors-%{+YYYY.MM.dd}"
    }
  }

  # Debug output (disable in production)
  if "${DEBUG_LOGGING:false}" == "true" {
    stdout {
      codec => rubydebug
    }
  }
}