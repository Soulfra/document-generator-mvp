#!/bin/bash

# ğŸ¤–ğŸš€ MULTI-LLM FORUM LAUNCHER
# Complete forum system with 8-hop Multi-LLM routing

echo "ğŸ¤– =============================================="
echo "ğŸ¤–    CAL MULTI-LLM FORUM SYSTEM LAUNCHER     "
echo "ğŸ¤– =============================================="
echo ""

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Load environment variables
if [ -f .env ]; then
    echo "ğŸ“ Loading environment variables from .env..."
    set -a
    source .env
    set +a
    echo -e "${GREEN}âœ… Environment loaded${NC}"
else
    echo -e "${YELLOW}âš ï¸  No .env file found - using system environment only${NC}"
fi

# Check prerequisites
echo ""
echo -e "${BLUE}ğŸ” SYSTEM PREREQUISITES CHECK${NC}"
echo "=============================="

# Check Node.js
if command -v node &> /dev/null; then
    NODE_VERSION=$(node --version)
    echo -e "${GREEN}âœ… Node.js: ${NODE_VERSION}${NC}"
else
    echo -e "${RED}âŒ Node.js: Not installed${NC}"
    echo "   Please install Node.js from https://nodejs.org/"
    exit 1
fi

# Check required files
REQUIRED_FILES=(
    "FORUM-MULTI-LLM-ENGINE.js"
    "FORUM-MULTI-LLM-INTEGRATION.js"
    "PRODUCTION-FORUM-API-SERVER.js"
    "REAL-FORUM-INTERFACE.html"
    "MULTI-LLM-CONFIG.json"
)

echo ""
echo -e "${BLUE}ğŸ“ REQUIRED FILES CHECK${NC}"
echo "======================="

FILES_MISSING=0
for file in "${REQUIRED_FILES[@]}"; do
    if [ -f "$file" ]; then
        echo -e "  âœ… ${file}: ${GREEN}Found${NC}"
    else
        echo -e "  âŒ ${file}: ${RED}Missing${NC}"
        FILES_MISSING=$((FILES_MISSING + 1))
    fi
done

if [ $FILES_MISSING -gt 0 ]; then
    echo -e "${RED}âŒ Missing required files. Please ensure all components are present.${NC}"
    exit 1
fi

# Check API keys
echo ""
echo -e "${BLUE}ğŸ” API KEY STATUS${NC}"
echo "================="

API_PROVIDERS=("ANTHROPIC_API_KEY" "OPENAI_API_KEY" "DEEPSEEK_API_KEY" "COHERE_API_KEY")
API_NAMES=("Anthropic Claude" "OpenAI GPT" "DeepSeek" "Cohere")
CONFIGURED_APIS=0

for i in "${!API_PROVIDERS[@]}"; do
    provider=${API_PROVIDERS[$i]}
    name=${API_NAMES[$i]}
    
    if [ -n "${!provider}" ]; then
        echo -e "  âœ… ${name}: ${GREEN}Configured${NC}"
        CONFIGURED_APIS=$((CONFIGURED_APIS + 1))
    else
        echo -e "  âš ï¸  ${name}: ${YELLOW}Not configured${NC}"
    fi
done

# Check local Ollama
if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo -e "  âœ… Local Ollama: ${GREEN}Running${NC}"
    CONFIGURED_APIS=$((CONFIGURED_APIS + 1))
else
    echo -e "  âš ï¸  Local Ollama: ${YELLOW}Not running${NC}"
fi

if [ $CONFIGURED_APIS -eq 0 ]; then
    echo ""
    echo -e "${RED}âŒ No AI providers configured!${NC}"
    echo -e "${YELLOW}ğŸ’¡ Run: ./setup-api-keys.sh to configure API keys${NC}"
    echo -e "${YELLOW}ğŸ’¡ Or install Ollama locally for free AI responses${NC}"
    exit 1
fi

echo -e "${GREEN}âœ… ${CONFIGURED_APIS} AI provider(s) available${NC}"

# Check if forum API is already running
API_RUNNING=$(lsof -ti:3334 2>/dev/null)

if [ ! -z "$API_RUNNING" ]; then
    echo ""
    echo -e "${GREEN}âœ… Forum API already running on port 3334${NC}"
else
    echo ""
    echo -e "${YELLOW}ğŸš€ Starting Multi-LLM Forum API Server...${NC}"
    
    # Install dependencies if needed
    if [ ! -d "node_modules" ]; then
        echo "ğŸ“¦ Installing Node.js dependencies..."
        npm install express sqlite3 cors ws axios uuid > /dev/null 2>&1
        echo -e "${GREEN}âœ… Dependencies installed${NC}"
    fi
    
    # Create integrated startup script
    cat > start-integrated-forum.js << 'EOF'
#!/usr/bin/env node

// Integrated Multi-LLM Forum Startup
const ProductionForumAPIServer = require('./PRODUCTION-FORUM-API-SERVER');
const ForumMultiLLMIntegration = require('./FORUM-MULTI-LLM-INTEGRATION');

async function startIntegratedForum() {
    console.log('ğŸš€ Starting Integrated Multi-LLM Forum System...\n');
    
    try {
        // Start the base forum API server
        console.log('1ï¸âƒ£ Initializing Production Forum API Server...');
        const ProductionForumAPIServerClass = ProductionForumAPIServer;
        const forumServer = new ProductionForumAPIServerClass();
        await forumServer.initialize();
        
        console.log('2ï¸âƒ£ Initializing Multi-LLM Integration...');
        const integration = new ForumMultiLLMIntegration(forumServer);
        await integration.initialize();
        
        console.log('\nğŸ‰ INTEGRATED MULTI-LLM FORUM SYSTEM READY!');
        console.log('============================================');
        console.log('ğŸŒ Forum Interface: Open REAL-FORUM-INTERFACE.html');
        console.log('ğŸ“¡ API Endpoint: http://localhost:3334/api');
        console.log('ğŸ“Š Dashboard: http://localhost:3334/dashboard');
        console.log('ğŸ”§ Health Check: http://localhost:3334/health');
        
        if (integration.initialized) {
            console.log('ğŸ¤– Multi-LLM Engine: ACTIVE');
            const patterns = integration.getHopPatterns();
            console.log(`ğŸ”„ Available Patterns: ${patterns.length}`);
            patterns.forEach(p => {
                console.log(`   â€¢ ${p.name}: ${p.hops.length} hops`);
            });
        } else {
            console.log('ğŸ”„ Multi-LLM Engine: Using fallback (local responses)');
        }
        
        console.log('\nğŸ’° Cost Tracking: Enabled');
        console.log('ğŸ“ˆ Real-time Metrics: Enabled');
        console.log('ğŸ”„ Auto-fallback: Enabled');
        console.log('\nâœ¨ Forum posts will now route through multiple AI providers! âœ¨');
        
        // Keep alive
        process.on('SIGINT', async () => {
            console.log('\n\nğŸ›‘ Shutting down...');
            await integration.shutdown();
            process.exit(0);
        });
        
    } catch (error) {
        console.error('âŒ Failed to start integrated forum system:', error.message);
        process.exit(1);
    }
}

startIntegratedForum();
EOF
    
    # Start the integrated system
    nohup node start-integrated-forum.js > multi-llm-forum.log 2>&1 &
    SERVER_PID=$!
    
    echo -e "${GREEN}âœ… Multi-LLM Forum API started (PID: $SERVER_PID)${NC}"
    echo -e "${BLUE}ğŸ“‹ Logs: tail -f multi-llm-forum.log${NC}"
    
    # Wait for server to start
    echo "â³ Waiting for server startup..."
    sleep 5
fi

# Check system health
echo ""
echo -e "${BLUE}ğŸ” SYSTEM HEALTH CHECK${NC}"
echo "====================="

# Check API health
if curl -s http://localhost:3334/health > /dev/null; then
    echo -e "${GREEN}âœ… API Server: Healthy${NC}"
    
    # Get server info
    SERVER_INFO=$(curl -s http://localhost:3334/health)
    echo -e "${BLUE}ğŸ“Š Server Status: ${SERVER_INFO}${NC}"
else
    echo -e "${YELLOW}âš ï¸  API Server: Starting up...${NC}"
    sleep 3
    if curl -s http://localhost:3334/health > /dev/null; then
        echo -e "${GREEN}âœ… API Server: Now healthy${NC}"
    else
        echo -e "${RED}âŒ API Server: Not responding${NC}"
        echo "Check logs: tail -f multi-llm-forum.log"
    fi
fi

# Check database
if [ -f "production-forum.db" ]; then
    POSTS=$(sqlite3 production-forum.db "SELECT COUNT(*) FROM forum_posts;" 2>/dev/null || echo "0")
    REPLIES=$(sqlite3 production-forum.db "SELECT COUNT(*) FROM forum_replies;" 2>/dev/null || echo "0")
    echo -e "${GREEN}âœ… Database: Connected (${POSTS} posts, ${REPLIES} replies)${NC}"
else
    echo -e "${YELLOW}âš ï¸  Database: Will be created on first post${NC}"
fi

echo ""
echo -e "${CYAN}ğŸ¤– MULTI-LLM FEATURES${NC}"
echo "===================="
echo -e "${GREEN}âœ¨ 8-hop routing through multiple AI providers${NC}"
echo -e "${GREEN}âœ¨ Intelligent pattern selection based on complexity${NC}"
echo -e "${GREEN}âœ¨ Real-time hop progress tracking${NC}"
echo -e "${GREEN}âœ¨ Cost optimization and budget limits${NC}"
echo -e "${GREEN}âœ¨ Automatic fallback to local responses${NC}"
echo -e "${GREEN}âœ¨ Visual hop chain display in forum${NC}"

echo ""
echo -e "${CYAN}ğŸ”„ HOP PATTERNS AVAILABLE${NC}"
echo "========================"
echo -e "${BLUE}â€¢ Simple (3 hops):${NC} Ollama â†’ Claude â†’ GPT-4"
echo -e "${BLUE}â€¢ Standard (5 hops):${NC} Ollama â†’ Claude â†’ DeepSeek â†’ Cohere â†’ GPT-4"
echo -e "${BLUE}â€¢ Legendary (8 hops):${NC} All providers + synthesis"
echo -e "${BLUE}â€¢ Cost Optimized:${NC} Mostly free providers"
echo -e "${BLUE}â€¢ Quality Focused:${NC} Premium providers only"

# Open forum interface
echo ""
echo -e "${PURPLE}ğŸŒŸ Opening Multi-LLM Cal Forum...${NC}"

# Try different methods to open the HTML file
if command -v open &> /dev/null; then
    # macOS
    open "REAL-FORUM-INTERFACE.html"
elif command -v xdg-open &> /dev/null; then
    # Linux
    xdg-open "REAL-FORUM-INTERFACE.html"
elif command -v start &> /dev/null; then
    # Windows
    start "REAL-FORUM-INTERFACE.html"
else
    echo -e "${YELLOW}âš ï¸  Could not auto-open browser${NC}"
    echo -e "${CYAN}   Manual: Open REAL-FORUM-INTERFACE.html in your browser${NC}"
fi

echo ""
echo -e "${GREEN}ğŸ‰ MULTI-LLM FORUM SYSTEM READY!${NC}"
echo ""
echo -e "${BLUE}ğŸ’¡ QUICK ACTIONS:${NC}"
echo "   ğŸ”„ View logs: tail -f multi-llm-forum.log"
echo "   ğŸ“Š API dashboard: open http://localhost:3334/dashboard"
echo "   ğŸ”§ Health check: curl http://localhost:3334/health"
echo "   ğŸ§ª Test Multi-LLM: node FORUM-MULTI-LLM-ENGINE.js test"
echo "   âš™ï¸  Setup API keys: ./setup-api-keys.sh"
echo ""
echo -e "${CYAN}ğŸ’° COST TRACKING:${NC}"
echo "   Current budget limit: \$${REQUEST_BUDGET_LIMIT:-0.50} per request"
echo "   Daily limit: \$${DAILY_BUDGET_LIMIT:-50.00}"
echo "   Costs are tracked in real-time and displayed in the forum"
echo ""
echo -e "${PURPLE}ğŸ›‘ TO STOP: kill \$(lsof -ti:3334)${NC}"
echo ""
echo -e "${CYAN}âœ¨ Your forum posts will now route through multiple AI providers! âœ¨${NC}"
echo -e "${CYAN}âœ¨ Watch the hop chains in real-time as responses are generated! âœ¨${NC}"