#!/usr/bin/env node

/**
 * MONKEY MODE - KEEP IT SIMPLE STUPID
 * Just make shit work without 111 layers of bullshit
 */

console.log(`
üêµ MONKEY MODE ACTIVATED üêµ
Smashing buttons until something works!
No orchestrators, no 111 layers, just KISS
`);

// What actually fucking works right now
const WORKING_SHIT = {
  'Ollama Local LLMs': 'http://localhost:11434',
  'LLM Router': 'http://localhost:4000', 
  'Semantic Search': 'http://localhost:5001',
  'Some Electron App': 'Running somewhere',
  'Real Business Data': 'Can process with local LLMs'
};

// Simple test - does it work or not?
async function monkeyTest() {
  console.log('üçå TESTING WHAT ACTUALLY WORKS:\n');
  
  for (const [name, url] of Object.entries(WORKING_SHIT)) {
    try {
      if (url.startsWith('http')) {
        const response = await fetch(url + '/health').catch(() => 
          fetch(url + '/api/tags').catch(() => 
            fetch(url))
        );
        console.log(`‚úÖ ${name}: WORKING (${url})`);
      } else {
        console.log(`‚ùì ${name}: ${url}`);
      }
    } catch (e) {
      console.log(`‚ùå ${name}: DEAD`);
    }
  }
}

// The ACTUAL simple thing that works
async function actuallyProcessDocument(text) {
  console.log('\nüêí MONKEY PROCESSING DOCUMENT...\n');
  
  // Use LOCAL LLM first (no API keys needed)
  try {
    const response = await fetch('http://localhost:11434/api/generate', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: 'codellama:7b',
        prompt: `Turn this into a working app idea: ${text}`,
        stream: false
      })
    });
    
    const result = await response.json();
    console.log('üçå LOCAL LLM SAYS:', result.response);
    
    // Save it somewhere simple
    const fs = require('fs');
    fs.writeFileSync('./monkey-output.txt', result.response);
    console.log('\n‚úÖ Saved to monkey-output.txt');
    
    // Make a simple HTML file
    const html = `
<!DOCTYPE html>
<html>
<head>
  <title>üêµ Monkey Made This</title>
  <style>
    body { 
      background: #000; 
      color: #0f0; 
      font-family: monospace; 
      padding: 50px;
    }
    .container {
      max-width: 800px;
      margin: 0 auto;
      border: 3px solid #0f0;
      padding: 30px;
    }
    h1 { text-align: center; }
    pre { 
      background: #111; 
      padding: 20px; 
      overflow-x: auto;
      white-space: pre-wrap;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>üêµ MONKEY MODE OUTPUT üêµ</h1>
    <h2>Original Input:</h2>
    <pre>${text}</pre>
    
    <h2>What The AI Said:</h2>
    <pre>${result.response}</pre>
    
    <h2>It Actually Works!</h2>
    <p>This was generated by just calling Ollama directly. No 111 layers needed.</p>
    <p>Generated at: ${new Date().toLocaleString()}</p>
  </div>
</body>
</html>`;
    
    fs.writeFileSync('./monkey-output.html', html);
    console.log('‚úÖ Created monkey-output.html');
    console.log('\nüéâ DONE! Open monkey-output.html in your browser');
    
    return true;
    
  } catch (error) {
    console.log('üí• MONKEY ERROR:', error.message);
    console.log('üîß Make sure Ollama is running: ollama serve');
    return false;
  }
}

// KISS Command Line
const args = process.argv.slice(2);
const command = args[0];

if (command === 'test') {
  monkeyTest();
} else if (command === 'process') {
  const text = args.slice(1).join(' ') || 'Build me a todo app that actually works';
  actuallyProcessDocument(text);
} else {
  console.log(`
üêµ MONKEY MODE USAGE:
  
  node monkey-mode-kiss.js test
    Test what's actually working
    
  node monkey-mode-kiss.js process "your idea here"  
    Process text with LOCAL LLM and get HTML output
    
  Example:
    node monkey-mode-kiss.js process "Build a meditation timer app"
    
  NO ORCHESTRATORS! NO 111 LAYERS! JUST WORKS!
  `);
}

// If no command, just run both
if (!command) {
  (async () => {
    await monkeyTest();
    console.log('\n---\n');
    await actuallyProcessDocument('Build a simple app that tracks daily water intake');
  })();
}